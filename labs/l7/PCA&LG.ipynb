{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "sc= SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = sqlContext.read.format('csv').options(inferSchema='true', header='true').load('file:///home/pgroup1/l7/PBMC_16k_RNA.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.groupby().max('KLHL17').first().asDict()['max(KLHL17)'] - df.groupby().min('KLHL17').first().asDict()['min(KLHL17)']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10.11507928"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.groupby().max('HES4').first().asDict()['max(HES4)'] - df.groupby().min('HES4').first().asDict()['min(HES4)']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10.812213"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = df.drop('index')\n",
    "old_cols = df.columns\n",
    "new_cols = df.columns\n",
    "\n",
    "for i in range(len(new_cols)):\n",
    "    new_cols[i] = new_cols[i].replace('.','')\n",
    "\n",
    "df = reduce(lambda data, idx: data.withColumnRenamed(old_cols[idx], new_cols[idx]), tqdm(range(len(old_cols))), df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1882/1882 [08:46<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.write.option('header','true').option('inferSchema', 'true').csv(\"file:///home/pgroup1/l7/PBMC_col_revised.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "assembler = VectorAssembler(inputCols=df.columns, outputCol=\"features\")\n",
    "features = assembler.transform(df).select(\"features\")\n",
    "\n",
    "pca = PCA(k=2, inputCol='features')\n",
    "pca.setOutputCol(\"pca_features\")\n",
    "model = pca.fit(features)\n",
    "model.explainedVariance"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DenseVector([0.0294, 0.0131])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "result = model.transform(features).select(\"pca_features\")\n",
    "result.show(1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n",
      "|        pca_features|\n",
      "+--------------------+\n",
      "|[7.46652731979111...|\n",
      "+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "y = sqlContext.read.format('csv').options(inferSchema='true', header='true').load('file:///home/pgroup1/l7/PBMC_16k_RNA_label.csv')\n",
    "y.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- CITEsort: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SGD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql.window import Window\n",
    "result = result.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "result.show(1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+---------+\n",
      "|        pca_features|row_index|\n",
      "+--------------------+---------+\n",
      "|[7.46652731979111...|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "y = y.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "y.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------+--------+---------+\n",
      "|             index|CITEsort|row_index|\n",
      "+------------------+--------+---------+\n",
      "|AAGGTTCTCAGTTTGG-1|     ACT|        1|\n",
      "|CGGACGTAGAAACGCC-1|  C-mono|        2|\n",
      "|GGCTCGATCCTAAGTG-1|  CD4+ T|        3|\n",
      "|TACACGACAATAGCGG-1|  CD4+ T|        4|\n",
      "|TCAATCTCATTCGACA-1|  CD8+ T|        5|\n",
      "+------------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "result = result.join(y, on=[\"row_index\"]).drop(\"row_index\")\n",
    "result.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------------------+--------+\n",
      "|        pca_features|             index|CITEsort|\n",
      "+--------------------+------------------+--------+\n",
      "|[7.46652731979111...|AAGGTTCTCAGTTTGG-1|     ACT|\n",
      "|[-4.4924025163180...|CGGACGTAGAAACGCC-1|  C-mono|\n",
      "|[2.61741671706775...|GGCTCGATCCTAAGTG-1|  CD4+ T|\n",
      "|[5.55800451104079...|TACACGACAATAGCGG-1|  CD4+ T|\n",
      "|[4.98150290491624...|TCAATCTCATTCGACA-1|  CD8+ T|\n",
      "|[4.57613006366093...|CTTACCGGTCGTTGTA-1|  CD4+ T|\n",
      "|[-7.8628762317470...|CCCAGTTTCCAGGGCT-1| NC-mono|\n",
      "|[6.98638584301929...|AGAGCGAAGAATAGGG-1|  CD8+ T|\n",
      "|[8.91687773343435...|ACGGCCAAGGATTCGG-1|     ACT|\n",
      "|[-7.6157478596061...|ATCGAGTGTAATCGTC-1|     ACT|\n",
      "|[5.29679290463833...|GCGCAACGTGAGCGAT-1|     ACT|\n",
      "|[2.91381397038213...|CCCAGTTTCCGCGGTA-1|  CD8+ T|\n",
      "|[3.97114115574227...|GAGGTGAAGCTACCTA-1|     ACT|\n",
      "|[1.03882406794541...|CGTCTACAGCGGATCA-1|  CD4+ T|\n",
      "|[0.14270695568292...|CCAATCCGTGCCTGGT-1|  CD4+ T|\n",
      "|[2.97562961813030...|TGGCCAGGTGTGCCTG-1|  B cell|\n",
      "|[14.3869576747256...|AAGGTTCAGCGTGAGT-1|     mNK|\n",
      "|[11.0719627202645...|AACCATGTCTACCAGA-1|     mNK|\n",
      "|[-0.0577387949146...|CTGTGCTGTGAACCTT-1|  CD4+ T|\n",
      "|[6.76005656217870...|GTCATTTTCTACGAGT-1|     ACT|\n",
      "+--------------------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "result = result.drop('index')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "result = sqlContext.read.options(inferSchema='true', header='true').load('dataset')\n",
    "result.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------+\n",
      "|        pca_features|CITEsort|\n",
      "+--------------------+--------+\n",
      "|[7.46652731979111...|     ACT|\n",
      "|[-4.4924025163180...|  C-mono|\n",
      "|[2.61741671706775...|  CD4+ T|\n",
      "|[5.55800451104079...|  CD4+ T|\n",
      "|[4.98150290491624...|  CD8+ T|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from pyspark.mllib.util import MLUtils\n",
    "result = MLUtils.convertVectorColumnsFromML(result, \"pca_features\")\n",
    "result.write.option('header','true').option('inferSchema', 'true').save(\"file:///home/pgroup1/l7/dataset\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we check which cell type has the greatest number (our a-cell)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "y['CITEsort'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CD4+ T     5262\n",
       "ACT        2952\n",
       "C-mono     2313\n",
       "CD8+ T     2035\n",
       "mNK        1057\n",
       "NC-mono     537\n",
       "B cell      414\n",
       "mDC         303\n",
       "DNT         178\n",
       "CD4+ DC     166\n",
       "iNK         113\n",
       "CD8+ DC      81\n",
       "Name: CITEsort, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "result.createOrReplaceTempView('data')\n",
    "a_cell = sqlContext.sql(\"select pca_features from data where CITEsort == 'CD4+ T'\")\n",
    "a_cell.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n",
      "|        pca_features|\n",
      "+--------------------+\n",
      "|[2.61741671706775...|\n",
      "|[5.55800451104079...|\n",
      "|[4.57613006366093...|\n",
      "|[1.03882406794541...|\n",
      "|[0.14270695568292...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "non_a_cell = sqlContext.sql(\"select pca_features from data where CITEsort != 'CD4+ T'\")\n",
    "non_a_cell.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n",
      "|        pca_features|\n",
      "+--------------------+\n",
      "|[7.46652731979111...|\n",
      "|[-4.4924025163180...|\n",
      "|[4.98150290491624...|\n",
      "|[-7.8628762317470...|\n",
      "|[6.98638584301929...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label the vector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "a_cell_rdd = a_cell.rdd.map(lambda x: LabeledPoint(1,x[0]))\n",
    "non_a_cell_rdd = non_a_cell.rdd.map(lambda x: LabeledPoint(0,x[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data = a_cell_rdd.union(non_a_cell_rdd)\n",
    "(train, test) = data.randomSplit([0.7,0.3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "logistic_model = LogisticRegressionWithLBFGS.train(train,numClasses=2, regParam=0,\n",
    "                                                               intercept=True,\n",
    "                                                               validateData=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict on the test dataset & Calculate the error rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "labels_and_predictions = test.map(lambda x: (x.label, logistic_model.predict(x.features)))\n",
    "error_rate = labels_and_predictions.filter(lambda x: x[0] != x[1]).count() / float(test.count())\n",
    "error_rate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.32744535217487303"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "0874a308516c769a9cf10ac69fdc7c3c01e983afbdfc67ac46c726fad050509e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}